{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f821bd44-3437-4584-9d0f-2a4da7a77635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from rkan.torch import JacobiRKAN, PadeRKAN\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0362d-6f61-4ef7-8f59-650b552a2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.jacobies = []\n",
    "        self.hiddens = []\n",
    "        for i in range(2, 7):\n",
    "            # act = JacobiRKAN(i)\n",
    "            act = PadeRKAN(i, 6)\n",
    "            # act = nn.Tanh()\n",
    "            self.jacobies.append(act)\n",
    "            self.hiddens.append(nn.Linear(1, 10))\n",
    "        self.output = nn.Linear(10 * len(self.jacobies), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        acts = []\n",
    "        for hidden, jacobi in zip(self.hiddens, self.jacobies):\n",
    "            q = hidden(x)\n",
    "            acts.append(jacobi(q))\n",
    "        h = torch.cat(acts, dim=1)\n",
    "        output = self.output(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2345a65a-cfb2-407e-b633-a2415d02ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dy_dx(y, x):\n",
    "    return torch.autograd.grad(\n",
    "        y, x, grad_outputs=torch.ones_like(y), create_graph=True\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466e49ed-a1f5-47c4-8c4f-82a7f66c6101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    loss = get_loss(x)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d75fc0-ad6b-4bbf-9c7c-477156a08f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(x):\n",
    "    global m\n",
    "    y = mlp.forward(x)\n",
    "    y_x = dy_dx(y, x)\n",
    "    y_xx = dy_dx(y_x, x)\n",
    "    residual = x * y_xx + 2 * y_x + x * y**m\n",
    "    initial1 = y[0] - 1  # float\n",
    "    initial2 = y_x[0] - 0  # float\n",
    "\n",
    "    loss = 1e5 * ((residual**2).mean() + initial1**2 + initial2**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ba7d22-4dff-4fe1-a359-c78d97cc981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(mlp, start, end, root_state_of_the_art):\n",
    "    x_test = torch.linspace(start, end, 100000)[1:].reshape(-1, 1)\n",
    "    predict = mlp.forward(x_test).detach()\n",
    "    indx_root = torch.argmin(torch.abs(predict))\n",
    "    return x_test[indx_root].item() - root_state_of_the_art\n",
    "\n",
    "\n",
    "params_for_m = [\n",
    "    {\"start\": 2, \"end\": 3, \"root_state_of_the_art\": 2.44948974},\n",
    "    {\"start\": 3, \"end\": 4, \"root_state_of_the_art\": 3.14159265},\n",
    "    {\"start\": 4, \"end\": 5, \"root_state_of_the_art\": 4.35287460},\n",
    "    {\"start\": 6, \"end\": 7, \"root_state_of_the_art\": 6.8968486},\n",
    "    {\"start\": 14, \"end\": 15, \"root_state_of_the_art\": 14.9715463},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4383a07-4dab-49a1-8e10-88c6e1fc5768",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 4\n",
    "score_params = params_for_m[m]\n",
    "\n",
    "x = torch.linspace(0, score_params[\"end\"], 1501, requires_grad=True).reshape(-1, 1)\n",
    "\n",
    "mlp = Model()\n",
    "optimizer = optim.LBFGS(list(mlp.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa165b2d-ad27-41ac-bdec-a881958b7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "scores = []\n",
    "for i in range(50):\n",
    "    loss = get_loss(x)\n",
    "    optimizer.step(closure)\n",
    "    losses.append(loss.detach().numpy())\n",
    "    scores.append(get_score(mlp, **score_params))\n",
    "    if i % 1 == 0:\n",
    "        print(\n",
    "            \"Epoch %3d: Current loss: %.2e, Error Predicted Root: %.2e\"\n",
    "            % (i, losses[-1], scores[-1])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312194d7-9c86-486a-99ff-5258ba31c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best score: %.2e\" % min(scores, key=abs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7658a-ad72-4214-9578-a48630831bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "x_test = torch.linspace(0, x[-1, 0], 10000)[1:].reshape(-1, 1)\n",
    "\n",
    "predict = mlp.forward(x_test).detach().numpy()\n",
    "np.save(\"m-%d.npy\" % m, predict)\n",
    "\n",
    "axs[0].plot(x_test, predict, \"g-\", label=\"Predict\")\n",
    "\n",
    "axs[1].plot(np.log10(losses), \"c\", label=\"Loss\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55724e62-7a92-4fc6-a9d9-c1a586eb37f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
